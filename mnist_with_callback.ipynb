{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "introduction-tensorflow",
      "graded_item_id": "d6dew",
      "launcher_item_id": "FExZ4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "mnist with callback.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VQCVgCIBlwqk"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoyQ70H00_s"
      },
      "source": [
        "#MNIST with callback\n",
        "We have done classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbg8780BajBp"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rvXQGAA0ssC"
      },
      "source": [
        "\n",
        "def train_mnist():\n",
        "    # Define your own callback\n",
        "    class mycallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self,epoch, logs={}):\n",
        "            if (logs.get('accuracy')>0.99):\n",
        "                print (\"\\n Reached 99% accuracy. Stopping training\")\n",
        "                self.model.stop_training = True\n",
        "        \n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "   \n",
        "    # Scale train and test sets\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    \n",
        "    callbacks = mycallback()\n",
        "\n",
        "    # Build  a dense neural network\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    # compile your model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(\n",
        "                x_train,y_train,epochs=10,callbacks=[callbacks]\n",
        "            )\n",
        "    \n",
        "    return history.epoch, history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4qo2Bm2ajBz",
        "outputId": "af77b829-1a98-4c07-9c7c-addaadbb1a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_mnist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1996 - accuracy: 0.9412\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0796 - accuracy: 0.9760\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0519 - accuracy: 0.9841\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0369 - accuracy: 0.9882\n",
            "Epoch 5/10\n",
            "1847/1875 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9915\n",
            " Reached 99% accuracy. Stopping training\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0273 - accuracy: 0.9914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4], 0.9913666844367981)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQCVgCIBlwqk"
      },
      "source": [
        "# DIY\n",
        "\n",
        "The above code trains the model for 10 epochs or 99% training accuracy whichever comes first.\n",
        "\n",
        "Rewrite the above code so that the model trains for either 100 epochs or 97.9% accuracy over the the validation (or test set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP94WwiAdAY1"
      },
      "source": [
        "def train_mnist_with_validation():\n",
        "\n",
        "\n",
        "    # Define your own callback\n",
        "    class mycallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self,epoch, logs={}):\n",
        "            if (logs.get('val_accuracy')>0.99):\n",
        "                print (\"\\n Reached 99% accuracy over valiation set. Stopping training\")\n",
        "                self.model.stop_training = True\n",
        "        \n",
        "\n",
        "\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    # Scale train and test sets\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    \n",
        "    callbacks = mycallback()\n",
        "\n",
        "    # Build  a dense neural network\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    # compile your model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # model fitting\n",
        "    history = model.fit(\n",
        "                x_train,y_train,epochs=60,callbacks=[callbacks], validation_data=(x_test,y_test))\n",
        "              \n",
        "\n",
        "    \n",
        "    return history.epoch, history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQbZZfBllKk2",
        "outputId": "c8689c32-40ef-470d-ffb4-633e04528a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_mnist_with_validation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2009 - accuracy: 0.9416 - val_loss: 0.1061 - val_accuracy: 0.9656\n",
            "Epoch 2/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.0819 - val_accuracy: 0.9736\n",
            "Epoch 3/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0538 - accuracy: 0.9834 - val_loss: 0.0718 - val_accuracy: 0.9776\n",
            "Epoch 4/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0650 - val_accuracy: 0.9790\n",
            "Epoch 5/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0822 - val_accuracy: 0.9767\n",
            "Epoch 6/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0764 - val_accuracy: 0.9793\n",
            "Epoch 7/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0868 - val_accuracy: 0.9775\n",
            "Epoch 8/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0833 - val_accuracy: 0.9793\n",
            "Epoch 9/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0736 - val_accuracy: 0.9802\n",
            "Epoch 10/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0861 - val_accuracy: 0.9801\n",
            "Epoch 11/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0919 - val_accuracy: 0.9797\n",
            "Epoch 12/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
            "Epoch 13/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0888 - val_accuracy: 0.9817\n",
            "Epoch 14/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0990 - val_accuracy: 0.9822\n",
            "Epoch 15/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1058 - val_accuracy: 0.9810\n",
            "Epoch 16/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0990 - val_accuracy: 0.9816\n",
            "Epoch 17/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0915 - val_accuracy: 0.9831\n",
            "Epoch 18/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1054 - val_accuracy: 0.9820\n",
            "Epoch 19/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.1095 - val_accuracy: 0.9816\n",
            "Epoch 20/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1027 - val_accuracy: 0.9814\n",
            "Epoch 21/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0992 - val_accuracy: 0.9827\n",
            "Epoch 22/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1272 - val_accuracy: 0.9794\n",
            "Epoch 23/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1056 - val_accuracy: 0.9828\n",
            "Epoch 24/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1184 - val_accuracy: 0.9797\n",
            "Epoch 25/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1089 - val_accuracy: 0.9843\n",
            "Epoch 26/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1275 - val_accuracy: 0.9821\n",
            "Epoch 27/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.1300 - val_accuracy: 0.9816\n",
            "Epoch 28/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1211 - val_accuracy: 0.9840\n",
            "Epoch 29/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1418 - val_accuracy: 0.9801\n",
            "Epoch 30/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1568 - val_accuracy: 0.9795\n",
            "Epoch 31/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1302 - val_accuracy: 0.9838\n",
            "Epoch 32/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1476 - val_accuracy: 0.9808\n",
            "Epoch 33/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1593 - val_accuracy: 0.9808\n",
            "Epoch 34/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1347 - val_accuracy: 0.9838\n",
            "Epoch 35/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1543 - val_accuracy: 0.9820\n",
            "Epoch 36/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1408 - val_accuracy: 0.9830\n",
            "Epoch 37/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1519 - val_accuracy: 0.9833\n",
            "Epoch 38/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1445 - val_accuracy: 0.9824\n",
            "Epoch 39/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1594 - val_accuracy: 0.9820\n",
            "Epoch 40/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1557 - val_accuracy: 0.9825\n",
            "Epoch 41/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1553 - val_accuracy: 0.9835\n",
            "Epoch 42/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1648 - val_accuracy: 0.9828\n",
            "Epoch 43/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1540 - val_accuracy: 0.9839\n",
            "Epoch 44/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1851 - val_accuracy: 0.9821\n",
            "Epoch 45/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1631 - val_accuracy: 0.9838\n",
            "Epoch 46/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.2144 - val_accuracy: 0.9794\n",
            "Epoch 47/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1823 - val_accuracy: 0.9823\n",
            "Epoch 48/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1874 - val_accuracy: 0.9822\n",
            "Epoch 49/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1811 - val_accuracy: 0.9818\n",
            "Epoch 50/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1744 - val_accuracy: 0.9831\n",
            "Epoch 51/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1941 - val_accuracy: 0.9812\n",
            "Epoch 52/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1981 - val_accuracy: 0.9824\n",
            "Epoch 53/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2007 - val_accuracy: 0.9818\n",
            "Epoch 54/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1946 - val_accuracy: 0.9833\n",
            "Epoch 55/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1846 - val_accuracy: 0.9831\n",
            "Epoch 56/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1936 - val_accuracy: 0.9826\n",
            "Epoch 57/60\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1967 - val_accuracy: 0.9830\n",
            "Epoch 58/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1711 - val_accuracy: 0.9841\n",
            "Epoch 59/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2173 - val_accuracy: 0.9806\n",
            "Epoch 60/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.2097 - val_accuracy: 0.9829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  48,\n",
              "  49,\n",
              "  50,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  55,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59],\n",
              " 0.9987666606903076)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiXjdnfclP4i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}